{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train: Loss = 0.24470341840060428\n",
      "Test:  Loss = 0.08160858153502146 Acc: 0.9759166666666667\n",
      "Epoch: 2\n",
      "Train: Loss = 0.061096217403246555\n",
      "Test:  Loss = 0.050274733527501426 Acc: 0.9847833333333333\n",
      "Epoch: 3\n",
      "Train: Loss = 0.039239700217876816\n",
      "Test:  Loss = 0.03247400665084521 Acc: 0.9903666666666666\n",
      "Epoch: 4\n",
      "Train: Loss = 0.031234498935191368\n",
      "Test:  Loss = 0.023515976093212765 Acc: 0.99315\n",
      "Epoch: 5\n",
      "Train: Loss = 0.023477920290133625\n",
      "Test:  Loss = 0.0173862152757744 Acc: 0.9949666666666667\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "It's a mini CNN example of pytorch\n",
    "Li Teng \n",
    "29.06.2021\n",
    "'''\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as f\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dset\n",
    "\n",
    "BATCH_SIZE = 256\n",
    "EPOCHS = 5\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # use GPU if available\n",
    "\n",
    "class ConvNet(nn.Module):# inherit from nn.Module\n",
    "    \n",
    "    def __init__(self):#init the module\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1,10,5)\n",
    "        self.conv2 = nn.Conv2d(10,20,3)\n",
    "        self.fc1 = nn.Linear(2000, 500) #input 20*10*10, out 500\n",
    "        self.fc2 = nn.Linear(500, 10) # 10 classes\n",
    "        \n",
    "    def forward(self,x):#forward propagation\n",
    "        in_size = x.size(0) # batch*1*28*28\n",
    "        x = self.conv1(x) # batch*1*28*28 -> batch*10*24*24\n",
    "        x = f.max_pool2d(f.relu(x),2) # batch*10*24*24 -> batch*10*12*12\n",
    "        x = self.conv2(x) # batch*10*12*12 ->batch*20*10*10\n",
    "        x = f.relu(x)\n",
    "        x = x.view(in_size,-1) # flat batch*20*10*10 -> batch*2000\n",
    "        x = self.fc1(x) # batch*2000 -> batch*500\n",
    "        x = f.relu(x)\n",
    "        x = self.fc2(x) # batch*500 -> batch*10\n",
    "        x = f.log_softmax(x,dim=1) # 'dim=1' means logsoftmax along 10 not batch\n",
    "        return x\n",
    "\n",
    "\n",
    "def data_process(): #data processing\n",
    "    transform = transforms.Compose([transforms.ToTensor(), # range [0, 255] -> [0.0,1.0]\n",
    "                                    transforms.Normalize((0.5,), (0.5,)) # range [0.0,1.0] -> [-1.0,1.0]\n",
    "                                   ])\n",
    "\n",
    "    data_train = dset.MNIST(root = \"./data/\",\n",
    "                            transform=transform,\n",
    "                            train = True,\n",
    "                            download = True)\n",
    "\n",
    "    data_test = dset.MNIST(root = \"./data/\",\n",
    "                           transform=transform,\n",
    "                           download = True)\n",
    "\n",
    "    data_loader_train = torch.utils.data.DataLoader(dataset=data_train,\n",
    "                                                    batch_size = BATCH_SIZE,\n",
    "                                                    shuffle = True)\n",
    "\n",
    "    data_loader_test = torch.utils.data.DataLoader(dataset=data_test,\n",
    "                                                   batch_size = BATCH_SIZE,\n",
    "                                                   shuffle = True)\n",
    "    \n",
    "    return data_loader_train, data_loader_test\n",
    "\n",
    "def train(model, device, train_loader, optimizer):\n",
    "    model.train() # model in train function\n",
    "    Loss_sum = 0 # sum loss of the every batch\n",
    "    Loss_avg = 0 # to comput average loss for each epoch\n",
    "    for data, target in train_loader:\n",
    "        data, target = data.to(device), target.to(device)# copy data to device\n",
    "        optimizer.zero_grad() # gradient to 0 before each batch\n",
    "        output = model(data) # forward propagation\n",
    "        loss = f.nll_loss(output, target) # loss_function = log_likelihood\n",
    "        loss.backward() # compute the gradients\n",
    "        optimizer.step() # update weights\n",
    "        Loss_sum += loss.item()\n",
    "    Loss_avg = Loss_sum/BATCH_SIZE\n",
    "    print(\"Train: Loss =\",Loss_avg)\n",
    "    \n",
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    Loss = 0 \n",
    "    Correct = 0 # count the number of correct prediction\n",
    "    with torch.no_grad(): # dont need back propagation\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            predict = output.max(1, keepdim=True)[1] # predict the label\n",
    "            Loss += f.nll_loss(output, target, reduction='sum').item() # same as training, sum loss for every case in batch\n",
    "            Correct += predict.eq(target.view_as(predict)).sum().item()\n",
    "        Loss /= len(test_loader.dataset)\n",
    "        Correct /= len(test_loader.dataset)\n",
    "        print(\"Test:  Loss =\",Loss,\"Acc:\",Correct)\n",
    "\n",
    "model = ConvNet().to(DEVICE)\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "Train_loader,Test_loader = data_process()\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    print(\"Epoch:\",epoch)\n",
    "    train(model, DEVICE, Train_loader, optimizer)\n",
    "    test(model, DEVICE, Test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
